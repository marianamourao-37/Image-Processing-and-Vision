{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbpBJnamz2Nf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import zipfile as zf\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import random\n",
    "import math\n",
    "import scipy.ndimage\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize as opt\n",
    "import matplotlib.image as img\n",
    "from scipy.ndimage import median_filter\n",
    "import sys\n",
    "\n",
    "# global variables:\n",
    "MIN_MATCH_COUNT = 24 # minimum number of matches required \n",
    "NUM_MATCH = 500 # total number of matches that we want to subsample from different locations of the image.\n",
    "                # For every region in the image analysed, if it contains at least a descriptor, and \n",
    "                # if the number of descriptors subsampled is fixed to N = 1, there will be 500 matches. \n",
    "                # Nevertheless, some regions of the image can have no descriptors, so the total number of matches will be reduced. \n",
    "                # For solving this, we can sample N > 1 descriptors from the regions of the image analysed \n",
    "\n",
    "MAX_ITER = 600 # number of iterations in ransac\n",
    "threshold_error = 4 # threshold error for points to be considered inliers, when performing ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features(des_src, des_dest, threshold):\n",
    "    '''\n",
    "    Implements the Nearest Neighbor Distance Ratio Test (NNDR) - Equation 4.18 in Section 4.1.3 of \n",
    "    Szeliski - to assign matches between interest points in two images. It also searches for mutual \n",
    "    matches and applies the NNDR test\n",
    "  \n",
    "    A match is between a feature in im1_features and a feature in im2_features. We can\n",
    "    represent this match as a the index of the feature in im1_features and the index\n",
    "    of the feature in im2_features\n",
    "    \n",
    "    :params:\n",
    "    :des_src: an np array of features for interest points in source image\n",
    "    :des_dest: an np array of features for interest points in destination image\n",
    "    \n",
    "    :returns:\n",
    "    :matches: an np array of dimension k x 2 where k is the number of matches. The first\n",
    "            column is an index into im1_features and the second column is an index into im2_features\n",
    "    '''\n",
    "    \n",
    "    global MIN_MATCH_COUNT\n",
    "\n",
    "    matches = []\n",
    "    \n",
    "    # Re-normalize\n",
    "    des_dest_normalize = des_dest / np.linalg.norm(des_dest, axis = 0)\n",
    "    \n",
    "    des_src_normalize = des_src / np.linalg.norm(des_src, axis = 0)\n",
    "    \n",
    "    # cosine similarity (descriptors are L2 normalized) \n",
    "    matrix_similarity = des_src_normalize.T @ des_dest_normalize\n",
    "    \n",
    "    ind_col_matches = np.argmax(matrix_similarity, axis = 1)\n",
    "        \n",
    "    matches = np.concatenate((np.arange(0, des_src.shape[1]).reshape(-1,1), ind_col_matches.reshape(-1, 1)), axis = 1)\n",
    "    final_matches = matches\n",
    "    \n",
    "    # FIND GOOD MATCHES:\n",
    "    # Retrieve top 2 nearest neighbors 1->2.\n",
    "    index_sorted = np.argsort(-matrix_similarity, axis = 1)[:, 0:2]\n",
    "\n",
    "    matrix_distances = np.sqrt(2 - 2 * matrix_similarity)\n",
    "    \n",
    "    mask_good_matches = matrix_distances[list(range(0,matrix_distances.shape[0])), index_sorted[:, 0]] / matrix_distances[list(range(0,matrix_distances.shape[0])), index_sorted[:, 1]] < threshold\n",
    "    \n",
    "    if np.any(mask_good_matches):\n",
    "        good_matches = matches[mask_good_matches, :]\n",
    "        \n",
    "        print(\"good matches/matches - %d/%d\" % (good_matches.shape[0],matches.shape[0]))\n",
    "        \n",
    "        if good_matches.shape[0] > MIN_MATCH_COUNT:\n",
    "            final_matches = good_matches\n",
    "    \n",
    "    # FIND MUTUAL AND GOOD MATCHES: \n",
    "    # Retrieve top 2 nearest neighbors 1->2.\n",
    "    matches_12_top2 = np.argsort(-matrix_similarity, axis = 1)[:, 0:2]\n",
    "    matches_12 = matches_12_top2[:, 0] # Save first NN and match similarity.\n",
    "    \n",
    "    matrix_distances = np.sqrt(2 - 2 * matrix_similarity)\n",
    "    \n",
    "    # Compute Lowe's ratio.\n",
    "    mask1_good_matches = matrix_distances[list(range(0,matrix_distances.shape[0])), matches_12_top2[:, 0]] / matrix_distances[list(range(0,matrix_distances.shape[0])), matches_12_top2[:, 1]] < threshold\n",
    "\n",
    "    # Retrieve top 2 nearest neighbors 1->2.\n",
    "    matches_21_top2 = np.argsort(-matrix_similarity.T, axis = 1)[:, 0:2]\n",
    "    matches_21 = matches_21_top2[:, 0] # Save first NN and match similarity.\n",
    "    \n",
    "    matrix_distances_T = np.sqrt(2 - 2 * matrix_similarity.T)\n",
    "    \n",
    "    # Compute Lowe's ratio.\n",
    "    mask2_good_matches = matrix_distances_T[list(range(0,matrix_distances_T.shape[0])), matches_21_top2[:, 0]] / matrix_distances_T[list(range(0,matrix_distances_T.shape[0])), matches_21_top2[:, 1]] < threshold\n",
    "        \n",
    "    final_mask_good_matches = mask1_good_matches & mask2_good_matches[matches_12]\n",
    "    \n",
    "    # Mutual NN + symmetric ratio test.\n",
    "    ids1 = np.arange(0, matrix_similarity.shape[0])\n",
    "    \n",
    "    mask_mutual_matches = (ids1 == matches_21[matches_12]) & final_mask_good_matches\n",
    "    \n",
    "    if np.any(mask_mutual_matches):\n",
    "        mutual_matches = matches[mask_mutual_matches, :]\n",
    "        \n",
    "        if mutual_matches.shape[0] > MIN_MATCH_COUNT:\n",
    "            final_matches = mutual_matches\n",
    "        \n",
    "        print(\"mutual and good matches/matches - %d/%d\" % (mutual_matches.shape[0],matches.shape[0]))\n",
    "\n",
    "    return final_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siftMatch(img1, img2, sift_path_ref, sift_path_image, threshold = 0.75, N = 1):\n",
    "    \n",
    "    global extract_sift, NUM_MATCH, subsampling\n",
    "    \n",
    "    if extract_sift:\n",
    "        sift = cv2.SIFT_create()\n",
    "        kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "        kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "        \n",
    "        m =match_features(des1.T,des2.T, threshold)\n",
    "        src_pts = np.float32([kp1[i].pt for i in m[:,0]]).reshape(-1,2)\n",
    "        dst_pts = np.float32([kp2[i].pt for i in m[:,1]]).reshape(-1,2)\n",
    "    \n",
    "    else:\n",
    "        data_ref = scipy.io.loadmat(sift_path_ref)\n",
    "        dst = data_ref['p'] # (2,N) numpy array, where N is the total number of keypoints\n",
    "        des_dest = data_ref['d'] # (128,N) numpy array, where N is the total number of keypoints\n",
    "        \n",
    "        data_image = scipy.io.loadmat(sift_path_image)\n",
    "        src = data_image['p'] # (2,N) numpy array, where N is the total number of keypoints\n",
    "        des_src = data_image['d'] # (128,N) numpy array, where N is the total number of keypoints\n",
    "        \n",
    "        if subsampling:\n",
    "            h, w, _ = img1.shape\n",
    "            \n",
    "            h_subsampling = math.floor(h/4) \n",
    "            \n",
    "            w_subsampling = math.floor(w * h/(NUM_MATCH*h_subsampling)) \n",
    "            \n",
    "            regions_h = range(0, h+1, h_subsampling)\n",
    "            regions_w = range(0, w+1, w_subsampling)\n",
    "            \n",
    "            des_src_subsampling = np.array([], dtype=np.int64).reshape(des_src.shape[0],0)\n",
    "            src_subsampling = np.array([], dtype=np.int64).reshape(src.shape[0],0)\n",
    "            \n",
    "            id_descriptor = np.arange(des_src.shape[1])\n",
    "            \n",
    "            for i in range(len(regions_h)-1):\n",
    "                h_region_min = regions_h[i]\n",
    "                h_region_max = regions_h[i+1]-1\n",
    "                \n",
    "                for j in range(len(regions_w)-1):\n",
    "                    w_region_min = regions_w[j]\n",
    "                    w_region_max = regions_w[j+1]-1\n",
    "                    \n",
    "                    ind_keypoints_region = (src[0,:] > w_region_min) & (src[0,:] < w_region_max) & (src[1,:] > h_region_min) & (src[1,:] < h_region_max)\n",
    "                    \n",
    "                    if np.any(ind_keypoints_region):\n",
    "                        if len(ind_keypoints_region[ind_keypoints_region == True]) < N:\n",
    "                            num_sampling = len(ind_keypoints_region[ind_keypoints_region == True])\n",
    "                            \n",
    "                        else:\n",
    "                            num_sampling = N \n",
    "                        \n",
    "                        ind_d_des = random.sample(list(id_descriptor[ind_keypoints_region]), num_sampling)\n",
    "                        \n",
    "                        des_src_subsampling = np.concatenate((des_src_subsampling, des_src[:, ind_d_des]), axis = 1)\n",
    "                        src_subsampling = np.concatenate((src_subsampling, src[:, ind_d_des]), axis = 1)\n",
    "            \n",
    "            des_src = des_src_subsampling\n",
    "            src = src_subsampling\n",
    "            \n",
    "        m =match_features(des_src,des_dest, threshold)\n",
    "        \n",
    "        matches_coords = np.concatenate((src[:, m[:,0]], dst[:, m[:, 1]]))\n",
    "        \n",
    "        src_pts = matches_coords[0:2, :].T\n",
    "        dst_pts = matches_coords[2:4, :].T\n",
    "            \n",
    "    return src_pts, dst_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5VodzFRoBnY"
   },
   "outputs": [],
   "source": [
    "def FitHomography(selected_matches, N = 4):\n",
    "    \"\"\" Compute the fitted homography matrix by using N match pairs\n",
    "  \n",
    "   [u]     [X]\n",
    "   [v] = H [Y], \n",
    "   [1]     [1]\n",
    "   being H a 3x3 matrix \n",
    "  \n",
    "   This can be arranged in a system Ax = 0, where x is a column vector with \n",
    "   the parameters of the homography, and A is given by:\n",
    "   A = [X Y 1 0 0 0 -u.X -u.Y -u]\n",
    "       [0 0 0 X Y 1 -v.X -v.Y -v]\n",
    "\n",
    "   For N matches, the above matrix is vertically stacked, with 2 rows per match \n",
    "  \"\"\"\n",
    "    \n",
    "    X = selected_matches[:,0]\n",
    "    Y = selected_matches[:,1]\n",
    "    u = selected_matches[:,2]\n",
    "    v = selected_matches[:,3]\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        row_1 = np.array([X[i], Y[i], 1, 0, 0, 0, -X[i]*u[i], -Y[i]*u[i], -u[i]])\n",
    "        row_2 = np.array([0, 0, 0, X[i], Y[i], 1, -X[i]*v[i], -Y[i]*v[i], -v[i]])\n",
    "        \n",
    "        A.append(row_1)\n",
    "        A.append(row_2)\n",
    "        \n",
    "    A = np.array(A)\n",
    "    \n",
    "    # V = eigvec(A.T @ A), being V.T obtained through Singular Value Decomposition (SVD)\n",
    "    _, _, vT = np.linalg.svd(A)\n",
    "\n",
    "  # vT is a 9×9 matrix\n",
    "  # the solution x is the eigenvector corresponding to the smallest eigenvalue, \n",
    "  # that is, the eigenvector corresponding to the minimum singular value, \n",
    "  # leading to a row vector of 9 columns. Thus, to obtain the calibrated \n",
    "  # homography H, the final solution is to reshape the obtained vector into a \n",
    "  # 3x3 matrix \n",
    "    H = np.reshape(vT[-1,:], (3,3))\n",
    "    \n",
    "    # normalized homography, dividing by the element at (3,3)\n",
    "    H = H/H[2,2]\n",
    "    \n",
    "    return H "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vhvGnyK2LbU"
   },
   "outputs": [],
   "source": [
    "def get_errors(all_matches, H):\n",
    "    \"\"\"Compute error or distance between original points and transformed by H. \n",
    "   Return an array of errors for all points\"\"\"\n",
    "    \n",
    "    num_matches = len(all_matches)\n",
    "    \n",
    "    X = all_matches[:,0].reshape(-1, 1)\n",
    "    Y = all_matches[:,1].reshape(-1, 1)\n",
    "    u = all_matches[:,2].reshape(-1, 1)\n",
    "    v = all_matches[:,3].reshape(-1, 1)\n",
    "    \n",
    "    # all matching points in source image\n",
    "    all_p1 = np.concatenate((X, Y, np.ones((len(all_matches),1))), axis = 1)\n",
    "    \n",
    "    # all matching points in template image\n",
    "    all_p2 = np.concatenate((u, v), axis = 1)\n",
    "    \n",
    "    # Transform every point in p1 to estimate p2\n",
    "    estimate_p2homogeneous = H @ all_p1.T\n",
    "    \n",
    "    estimate_p2euclidean = (estimate_p2homogeneous/(estimate_p2homogeneous[-1]))[0:2]\n",
    "    \n",
    "    # Compute error of each matching pair\n",
    "    errors = np.linalg.norm(all_p2 - estimate_p2euclidean.T, axis = 1) \n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImLjOO5V0TFB"
   },
   "outputs": [],
   "source": [
    "def GetHomographyRANSAC(match_coords):\n",
    "    \n",
    "    \"\"\"Function that computes linear (2D) Homography Calibration, implementing RANSAC\n",
    "  for eliminating outliers and align correspondent matches. The main output concerns \n",
    "  a single transformation H that gets the most inliers in the course of all the \n",
    "  iterations. \n",
    "  \n",
    "    Args:\n",
    "        match_coords(numpy.ndarray): In dims (#matched pixels, 4).\n",
    "\n",
    "    Returns:\n",
    "        H(numpy.ndarray): Homography matrix, dims (3, 3).\n",
    "    \"\"\"\n",
    "    \n",
    "    global MAX_ITER, threshold_error\n",
    "    \n",
    "    N = 4 # four matches to initialize the homography in each iteration\n",
    "    \n",
    "    max_inliers = 0 \n",
    "    \n",
    "    # RANSAC procedure\n",
    "    # (o numero de iterações baseei me aqui: https://engineering.purdue.edu/kak/courses-i-teach/ECE661.08/solution/hw4_s1.pdf)\n",
    "    \n",
    "    for itr in range(MAX_ITER): \n",
    "        # Randomly select 4 matched pairs\n",
    "        idx_rand_inliers = random.sample(range(match_coords.shape[0]), N)\n",
    "        \n",
    "        selected_matches = match_coords[idx_rand_inliers, :]\n",
    "        \n",
    "        # compute the homography H by DLT from the N = 4 matched pairs \n",
    "        H = FitHomography(selected_matches)\n",
    "        \n",
    "        # Find inliners \n",
    "        errors = get_errors(match_coords, H)\n",
    "        \n",
    "        idx_inliers = np.where(errors < threshold_error)[0]\n",
    "        \n",
    "        num_inliers = len(idx_inliers) \n",
    "        \n",
    "        # Analise current solution, and if it contains the maximum number of inliers\n",
    "        # amongst all homographies until now fitted, save the current inliers for \n",
    "        # further refinement of the homography in the last step \n",
    "        \n",
    "        if num_inliers > max_inliers:\n",
    "            max_inliers = num_inliers\n",
    "            best_inliers = match_coords[idx_inliers]\n",
    "    \n",
    "    # compute the homography H by DLT from best_inliers  \n",
    "    H = FitHomography(best_inliers, max_inliers)\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "br0AIm3Vwdh3"
   },
   "outputs": [],
   "source": [
    "def Check_Homography(image, H, image_paths, sift_paths, i):\n",
    "    \"\"\"\n",
    "  Check if homography is reasonable, according to certain criteria:\n",
    "  - If the determinant of the homography det(H) is very close to 0, H is \n",
    "   close to singular;\n",
    "  \n",
    "  - If condition number of H (ratio of the first-to-last singular value) is\n",
    "    infinite, the matrix H is singular, and if it is too large, H is \n",
    "    ill-conditioned. In non-mathematical terms, an ill-conditioned problem \n",
    "    is one where, for a small change in the inputs, there is a large \n",
    "    change in the output, that is, H is very sensitive to changes or errors \n",
    "    in the input. This means that the correct solution/answer to the \n",
    "    equation becomes hard to find;\n",
    "        \n",
    "  - If det(H) >>, the invert matrix would have a determinant too close \n",
    "    to 0, that is, H^-1 would be close to singular;\n",
    "        \n",
    "  - If det(H) < 0, the homography is not conserving the orientation, \n",
    "    being orientation-reversing. This is not suitable, except if we are \n",
    "    watching the object in a mirror. Nevertheless, sift/surf descriptors \n",
    "    are not done to be mirror invariant, so if it was the case we would \n",
    "    probably not have good maches. \n",
    "        \n",
    "  An exactly singular matrix means that it is not invertible. If the above \n",
    "  criteria is verified, more pratically the matrix H or H^-1 is non-invertible. \n",
    "  In the context of homographies, it means that points in one 2D image are mapped\n",
    "  to a less-than-2D subspace in the other image (a line, a point), i.e. \n",
    "  the estimated homography would be warping the image into nothing. A \n",
    "  nearly singular matrix is indicative of a rather extreme warp.  \n",
    "\n",
    "  \"\"\"\n",
    "    #Conditions to accertain that the resultant homography H is free of \n",
    "    #singularities. If one of the condition is satisfied, the Homography H from \n",
    "    #image space to reference image space is not reasonable, according \n",
    "    #to the defined criteria \n",
    "    \n",
    "    global last_H_good, last_iter_good, extract_sift \n",
    "    \n",
    "    if  np.linalg.det(H) <= 0.1 or np.linalg.cond(H[0:2, 0:2]) >= 3.25:\n",
    "        \n",
    "        # In the condition number, only the top-left 2x2 matrix is considered, \n",
    "        # thus omitting the z-dependence of the transformation, which should be \n",
    "        # irrelevant because we know that z will always be fixed to 1 on the input\n",
    "                \n",
    "        if last_iter_good != 0:\n",
    "            print('searching for a reasonable H')\n",
    "            # if in the current iteration no reasonable homography was estimated, \n",
    "            # the last homography that was found reasonable is considered \n",
    "            \n",
    "            I2_path = image_paths[last_iter_good]\n",
    "            I2 = img.imread(I2_path)\n",
    "            \n",
    "            if extract_sift:\n",
    "                sift_path1 = None\n",
    "                sift_path2 = None\n",
    "            else: \n",
    "                sift_path2 = sift_paths[last_iter_good]\n",
    "                sift_path1 = sift_paths[i]\n",
    "            \n",
    "            # homography from I2 to template \n",
    "            H_I2_template = last_H_good\n",
    "            \n",
    "            # match points between image (source space) and I2 (destination space)\n",
    "            m_coords_img, m_coords_temp = siftMatch(image, I2, sift_path2, sift_path1, N = 4)\n",
    "            match_coords = np.append(m_coords_img, m_coords_temp, axis = 1)\n",
    "            \n",
    "            # homography from image space to I2 space \n",
    "            H_image_I2 = GetHomographyRANSAC(match_coords)\n",
    "            \n",
    "            # Conjugate all the performed transformations from original to final warped\n",
    "            # image (image space--> H_image_I2 --> I2 space --> H_I2_template --> final warp image)\n",
    "            H = H_I2_template@H_image_I2\n",
    "            \n",
    "        # check if obtained homography is reasonable \n",
    "        if np.linalg.det(H) > 20 and np.linalg.cond(H[0:2, 0:2]) < 3.25:\n",
    "            last_iter_good = i \n",
    "            last_H_good = H\n",
    "            \n",
    "            # If the above strategy was not successful in estimating an homography between\n",
    "            # image and template, set H to 0 \n",
    "        else:\n",
    "            H = np.zeros((3,3))\n",
    "        \n",
    "    # Homography H from image space to template space is reasonable, according \n",
    "    # to the defined criteria \n",
    "    else:\n",
    "        last_iter_good = i \n",
    "        last_H_good = H\n",
    "        \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9TowchmKG3C"
   },
   "outputs": [],
   "source": [
    "def image_wrap(image, template, H):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that returns image into template perspective according to homography H, \n",
    "    by applying inverse mapping. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Coordinates of the template page corners\n",
    "    height,width,ch = template.shape\n",
    "    u_corners = np.array([0, width, width, 0])\n",
    "    v_corners = np.array([height, height, 0, 0])\n",
    "    \n",
    "    max_x = math.ceil(np.ndarray.max(u_corners))\n",
    "    max_y = math.ceil(np.ndarray.max(v_corners))\n",
    "    min_x = math.floor(np.ndarray.min(u_corners))\n",
    "    min_y = math.floor(np.ndarray.min(v_corners))\n",
    "    \n",
    "    # bounding box region of the warped image, created by a grid that has the \n",
    "    # same size as the template\n",
    "    x, y = np.meshgrid(range(min_x, max_x), range(min_y, max_y))\n",
    "    \n",
    "    # homogeneous coordinates in the grid\n",
    "    x_coords = x.flatten().reshape(1,-1)\n",
    "    y_coords = y.flatten().reshape(1,-1)\n",
    "    \n",
    "    grid_coords = np.concatenate((x_coords, y_coords, np.ones((1, x_coords.shape[1]))))\n",
    "    \n",
    "    # reverse warp by applying the inverse of our transformation matrix H\n",
    "    warp_coords_homogeneous  = np.linalg.solve(H, grid_coords)\n",
    "    \n",
    "    # To get the warped coordinates, we must divide the first and second coordinates by \n",
    "    # z to obtain the new x and y (euclidean coordinates)\n",
    "    z = warp_coords_homogeneous[None, 2, :]  \n",
    "    warp_coords = warp_coords_homogeneous[0:2, :]/np.concatenate((z,z))\n",
    "    \n",
    "    # Reshape the pixel grid to have the same size as the template  \n",
    "    x_warp = np.reshape(warp_coords[None, 0, :], (x.shape[0], x.shape[1]))\n",
    "    y_warp = np.reshape(warp_coords[None, 1, :], (y.shape[0], y.shape[1]))\n",
    "    \n",
    "    # Warped Image array that will contain RGB color maps obtained through inverse \n",
    "    # mapping \n",
    "    I_WarpColorMaps = np.zeros((template.shape[0], template.shape[1], image.shape[2]))\n",
    "    \n",
    "    # color interpolation, by sampling a color value for each pixel in source image. \n",
    "    # By doing this we won't have any black pixels or gaps in the warpped image, \n",
    "    # (a kind of undersampling artifact)\n",
    "    \n",
    "    for i in range(image.shape[2]):\n",
    "        # When mapping pixel locations, they most often will not fall exactly on a \n",
    "        # pixel in the source image. For solving this, we use nearest interpolation (order = 0)\n",
    "        # for assigning the color value\n",
    "        \n",
    "        I_WarpColorMaps[:, :, i] = scipy.ndimage.map_coordinates(image[:, :, i].astype(float), [y_warp, x_warp], order = 0)\n",
    "        \n",
    "        # color pixel warping, by converting I_WarpColorMaps into an unsigned 8-bit integer, \n",
    "        # with the elements of an uint8 ranging from 0 to 255\n",
    "        I = I_WarpColorMaps.astype('uint8')\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_skin(I_RGB, kernel_size = 3):\n",
    "    \"\"\"\n",
    "  Segmentation by partitioning of the colour space.\n",
    "  \"\"\"\n",
    "    \n",
    "    I_RGB[:,:,0] = median_filter(I_RGB[:,:,0], size=kernel_size)\n",
    "    I_RGB[:,:,1] = median_filter(I_RGB[:,:,1], size=kernel_size)\n",
    "    I_RGB[:,:,2] = median_filter(I_RGB[:,:,2], size=kernel_size)\n",
    "    \n",
    "    \n",
    "    # converting from rgb to hsv color space\n",
    "    I_HSV = cv2.cvtColor(I_RGB,cv2.COLOR_BGR2HSV)\n",
    "    H = I_HSV[:,:,0]\n",
    "    S = I_HSV[:,:,1]\n",
    "    V = I_HSV[:,:,2]\n",
    "    \n",
    "    #print(\"H:\", np.ndarray.max(H[1000:1500, 1500:]))\n",
    "    #print(\"H:\", np.ndarray.min(H[1000:1500, 1500:]))\n",
    "    #print(\"S:\", np.ndarray.max(S[1000:1500, 1500:]))\n",
    "    #print(\"S:\", np.ndarray.min(S[1000:1500, 1500:]))\n",
    "    #print(\"V:\", np.ndarray.max(V[1000:1500, 1500:]))\n",
    "    #print(\"V:\", np.ndarray.min(V[1000:1500, 1500:]))\n",
    "    \n",
    "    # define the upper and lower boundaries of the HSV pixel\n",
    "    # intensities to be considered 'skin'\n",
    "    lower = np.array([101, 50, 200], dtype = \"uint8\")\n",
    "    upper = np.array([120, 110, 255], dtype = \"uint8\")\n",
    "    \n",
    "    # determine the HSV pixel intensities that fall into\n",
    "    # the speicifed upper and lower boundaries\n",
    "    skinMask = cv2.inRange(I_HSV, lower, upper)\n",
    "        \n",
    "    # apply a 2 iterations of erosions and a 4 iterations of dilations, respectively, to the mask\n",
    "    # using an elliptical kernel, in order to remove small false-positive skin regions in the image. \n",
    "    kernel_erode = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20)) # create an elliptical structuring kernel\n",
    "    kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (100, 100))\n",
    "    \n",
    "    skinMask = cv2.erode(skinMask, kernel_erode, iterations = 2)\n",
    "\n",
    "    skinMask = cv2.dilate(skinMask, kernel_dilate, iterations = 4)\n",
    "    \n",
    "    # apply the mask to the frame\n",
    "    I_segmented = cv2.bitwise_and(I_RGB, I_RGB, mask = ~skinMask)\n",
    "    \n",
    "    return I_segmented, skinMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSgjoVMq0ATW"
   },
   "outputs": [],
   "source": [
    "def pivproject2022_task1_plus(path_to_template_folder, path_to_input_folder, path_to_output_folder, extract_sift, subsampling, cv2WarpPerspective, segment):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the homography between images in a directory and a template\n",
    "\n",
    "    path_to_template_folder:  string with the path to a folder with both the \n",
    "                               a jpg file for the template image\n",
    "                               and a mat file with the sift descriptors\n",
    "    \n",
    "    path_to_input_folder: string with the path to the input folder, where input images \n",
    "                           and keypoints are stored. Images are named rgb_number.jpg \n",
    "                           (or rgb_number.png) and corresponding keypoints are named \n",
    "                           rgbsift_number.mat\n",
    "\n",
    "    path_to_output_folder: string with the path where homographies between images and \n",
    "    the template are stored\n",
    "    \"\"\"\n",
    "    \n",
    "    global last_H_good, last_iter_good\n",
    "    \n",
    "    # Check if path_to_input_folder was passed. If not, \"No_path\" is assigned\n",
    "    if not('path_to_input_folder' in locals()):\n",
    "        path_to_input_folder = \"No_path\";\n",
    "        \n",
    "    # Check if output directory exists. If not, output directory is created \n",
    "    if not(os.path.isdir(path_to_output_folder)):\n",
    "        os.mkdir(path_to_output_folder)\n",
    "    \n",
    "    # Get input rgb images\n",
    "    rgb_paths = []\n",
    "    sift_paths = []\n",
    "\n",
    "    for im_path in glob.glob(path_to_input_folder+'/*.jpg'):\n",
    "        rgb_paths.append(im_path)\n",
    "    \n",
    "    if len(rgb_paths) == 0:\n",
    "        print('ERROR: In the specified path there aren\\'t image input files')\n",
    "        return \n",
    "    \n",
    "    else: \n",
    "        #Ordering the rgb_paths array, in such a way that consecutive frames follow \n",
    "        #each other  \n",
    "        image_paths = sorted(rgb_paths)  \n",
    "    \n",
    "    if not(extract_sift):\n",
    "        print('Searching for sift .mat files')\n",
    "        \n",
    "        for im_path in glob.glob(path_to_input_folder+'/*.mat'):\n",
    "            sift_paths.append(im_path)\n",
    "            \n",
    "            if len(sift_paths) != 0:\n",
    "                extract_sift = False\n",
    "                \n",
    "                sift_paths_ordered = sorted(sift_paths)\n",
    "            \n",
    "            else:\n",
    "                extract_sift = True\n",
    "                print('In the specified path there aren\\'t sift input files. Thus, a sift function will be used to extract matching points')\n",
    "    \n",
    "    # Get template image\n",
    "    try:\n",
    "        print('Searching for template')\n",
    "        \n",
    "        for path in glob.glob(path_to_template_folder+'/*.jpg'):\n",
    "            template_path = path\n",
    "            template = img.imread(template_path)\n",
    "    \n",
    "    except:\n",
    "        print('ERROR: ERROR: In the specified path there isn\\'t a template image, or the directory format ins\\'t compatible with OpenCV, as it only accepts ASCII characters for image paths')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        sift_template_path = template_path[:-4] + '.mat'\n",
    "    \n",
    "    except:\n",
    "        print('ERROR: In the specified path there is not a sift input file. Thus, a sift function will be used to extract matching points')\n",
    "    \n",
    "    \n",
    "    print('Calculating projections')\n",
    "        \n",
    "    last_image_no_skin = 0 # variable for saving the last iteration where an image without skin was registered \n",
    "    last_H_good = 0 # variable for saving the last reasonable homography estimated \n",
    "    last_iter_good = 0 # variable for saving the last iteration where a reasonable \n",
    "                       # homography was estimated \n",
    "    \n",
    "    for i in range(len(image_paths)):\n",
    "        print(str(i + 1), '/', str(len(image_paths)), 'Image to be processed')\n",
    "        \n",
    "        image_path = image_paths[i]\n",
    "        image = img.imread(image_path)\n",
    "        \n",
    "        if extract_sift:\n",
    "            sift_path = None\n",
    "        \n",
    "        else:\n",
    "            sift_path = sift_paths_ordered[i]\n",
    "        \n",
    "        try:\n",
    "            # coordinates of the matches between image and template \n",
    "            m_coords_img, m_coords_temp = siftMatch(image, template, sift_template_path, sift_path, N = 4) \n",
    "            match_coords = np.append(m_coords_img, m_coords_temp, axis = 1)\n",
    "        \n",
    "        except:\n",
    "            print('ERROR: check format of directory, as OpenCV only accepts ASCII characters for image paths')\n",
    "            return \n",
    "        \n",
    "        try:\n",
    "            H = GetHomographyRANSAC(match_coords)\n",
    "            \n",
    "            if extract_sift:\n",
    "                sift_paths_ordered = None\n",
    "                \n",
    "            # Check if homography is reasonable, according to certain criteria\n",
    "            H = Check_Homography(image, H, image_paths, sift_paths_ordered, i)\n",
    "            \n",
    "        except: \n",
    "            print('ERROR: RANSAC failed to compute homography. Check if there are enough matching keypoints.')\n",
    "        \n",
    "        # extract file name for saving subsequenlty the desired outputs in the output folder \n",
    "        file_name = os.path.split(image_path)[1]\n",
    "        \n",
    "        # if the homography is reasonable, perform image warping and segmentation (this last one if set to true) \n",
    "        if not(np.array_equal(H, np.zeros((3,3)))):\n",
    "\n",
    "            if cv2WarpPerspective:\n",
    "                I = cv2.warpPerspective(image, H, (template.shape[1], template.shape[0]), flags = cv2.INTER_NEAREST)\n",
    "            \n",
    "            else:\n",
    "                I = image_wrap(image, template, H)\n",
    "        \n",
    "            if segment:\n",
    "                I_segment, skinMask = segmentation_skin(I)\n",
    "                \n",
    "                if np.any(skinMask) & np.any(last_image_no_skin) != 0:\n",
    "                    masked_image = cv2.bitwise_and(last_image_no_skin, last_image_no_skin, mask = skinMask)\n",
    "                    \n",
    "                    I_final = (I_segment + masked_image).astype('uint8')\n",
    "                    \n",
    "                    # saving the segmented images \n",
    "                    image_segmented_output_path = path_to_output_folder + '/segmented_' + file_name\n",
    "                    cv2.imwrite(image_segmented_output_path, I_final)\n",
    "                    \n",
    "                    plt.subplot(133)\n",
    "                    plt.title('Segmented Image')\n",
    "                    plt.imshow(I_final)\n",
    "                    plt.axis('off')\n",
    "                \n",
    "                elif ~np.any(skinMask):\n",
    "                    last_image_no_skin = I \n",
    "                    I_final = I\n",
    "                    \n",
    "        # if the homography isnt reasonable, the final rendered image is set to zero\n",
    "        else:\n",
    "            I = np.zeros((template.shape[0], template.shape[1]))\n",
    "        \n",
    "        plt.subplot(131)\n",
    "        plt.title('original image')\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(132)\n",
    "        plt.title('Warped Image')\n",
    "        plt.imshow(I)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Saving outputs \n",
    "        H_output_path = path_to_output_folder + '/' + 'H_' + file_name[4:8] + '.mat'\n",
    "        scipy.io.savemat(H_output_path, {'H':H})\n",
    "        \n",
    "        # saving the rendered images in the template perspective \n",
    "        image_output_path = path_to_output_folder + '/' + file_name\n",
    "        cv2.imwrite(image_output_path, I)\n",
    "    \n",
    "    print('All projections calculated.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input variables: \n",
    "\n",
    "path_to_template_folder = 'DATASETS/formsns'\n",
    "path_to_input_folder = 'DATASETS/receitaSNS'\n",
    "path_to_output_folder = 'Output_folder_receitasns'\n",
    "\n",
    "cv2WarpPerspective = False # variable that tunes if image warping is to be performed by cv2WarpPerspective built-in function \n",
    "                           # or a function developed by the group \n",
    "    \n",
    "extract_sift = False # variable that tunes if the extraction of sift keypoints and descriptors is to be performed\n",
    "\n",
    "subsampling = True # variable that tunes the subsampling or not of the souce image descriptors, \n",
    "                   # when performing the matching \n",
    "\n",
    "segment = True # variable that tunes the skin segmentation or not of the warping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WB83jO0f1NPz",
    "outputId": "2658b361-acbb-4bff-eb70-c1b298bf4b6a"
   },
   "outputs": [],
   "source": [
    "pivproject2022_task1_plus(path_to_template_folder, path_to_input_folder, path_to_output_folder, extract_sift, subsampling, cv2WarpPerspective, segment)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
