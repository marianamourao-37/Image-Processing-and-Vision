{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ypREH_HYCQSV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import zipfile as zf\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import random\n",
    "import math\n",
    "import scipy.ndimage\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import sys\n",
    "\n",
    "# global variables:\n",
    "MIN_MATCH_COUNT = 24 # minimum number of matches required\n",
    "MAX_ITER = 5000 # number of iterations in ransac\n",
    "NUM_MATCH = 500 # total number of matches that we want to subsample from different locations of the image.\n",
    "                # For every region in the image analysed, if it contains at least a descriptor, and \n",
    "                # if the number of descriptors subsampled is fixed to N = 1, there will be 500 matches. \n",
    "                # Nevertheless, some regions of the image can have no descriptors, so the total number of matches will be reduced. \n",
    "                # For solving this, we can sample N > 1 descriptors from the regions of the image analysed \n",
    "\n",
    "subsampling = True # variable that tunes the subsampling or not of the souce image descriptors, \n",
    "                   # when performing the matching \n",
    "    \n",
    "threshold_error = 4 # threshold error for points to be considered inliers, when performing ransac "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features(des_src, des_dest, threshold):\n",
    "    '''\n",
    "    Implements the Nearest Neighbor Distance Ratio Test (NNDR) - Equation 4.18 in Section 4.1.3 of \n",
    "    Szeliski - to assign matches between interest points in two images. It also searches for mutual \n",
    "    matches and applies the NNDR test\n",
    "  \n",
    "    A match is between a feature in im1_features and a feature in im2_features. We can\n",
    "    represent this match as a the index of the feature in im1_features and the index\n",
    "    of the feature in im2_features\n",
    "    \n",
    "    :params:\n",
    "    :des_src: an np array of features for interest points in source image\n",
    "    :des_dest: an np array of features for interest points in destination image\n",
    "    \n",
    "    :returns:\n",
    "    :matches: an np array of dimension k x 2 where k is the number of matches. The first\n",
    "            column is an index into im1_features and the second column is an index into im2_features\n",
    "    '''\n",
    "    \n",
    "    global MIN_MATCH_COUNT\n",
    "\n",
    "    matches = []\n",
    "    \n",
    "    # Re-normalize\n",
    "    des_dest_normalize = des_dest / np.linalg.norm(des_dest, axis = 0)\n",
    "    \n",
    "    des_src_normalize = des_src / np.linalg.norm(des_src, axis = 0)\n",
    "    \n",
    "    # cosine similarity (descriptors are L2 normalized) \n",
    "    matrix_similarity = des_src_normalize.T @ des_dest_normalize\n",
    "    \n",
    "    ind_col_matches = np.argmax(matrix_similarity, axis = 1)\n",
    "        \n",
    "    matches = np.concatenate((np.arange(0, des_src.shape[1]).reshape(-1,1), ind_col_matches.reshape(-1, 1)), axis = 1)\n",
    "    final_matches = matches\n",
    "    \n",
    "    # FIND GOOD MATCHES:\n",
    "    # Retrieve top 2 nearest neighbors 1->2.\n",
    "    index_sorted = np.argsort(-matrix_similarity, axis = 1)[:, 0:2]\n",
    "\n",
    "    matrix_distances = np.sqrt(2 - 2 * matrix_similarity)\n",
    "    \n",
    "    mask_good_matches = matrix_distances[list(range(0,matrix_distances.shape[0])), index_sorted[:, 0]] / matrix_distances[list(range(0,matrix_distances.shape[0])), index_sorted[:, 1]] < threshold\n",
    "    \n",
    "    if np.any(mask_good_matches):\n",
    "        good_matches = matches[mask_good_matches, :]\n",
    "        \n",
    "        print(\"good matches/matches - %d/%d\" % (good_matches.shape[0],matches.shape[0]))\n",
    "        \n",
    "        if good_matches.shape[0] > MIN_MATCH_COUNT:\n",
    "            final_matches = good_matches\n",
    "    \n",
    "    # FIND MUTUAL AND GOOD MATCHES: \n",
    "    # Retrieve top 2 nearest neighbors 1->2.\n",
    "    matches_12_top2 = np.argsort(-matrix_similarity, axis = 1)[:, 0:2]\n",
    "    matches_12 = matches_12_top2[:, 0] # Save first NN and match similarity.\n",
    "    \n",
    "    matrix_distances = np.sqrt(2 - 2 * matrix_similarity)\n",
    "    \n",
    "    # Compute Lowe's ratio.\n",
    "    mask1_good_matches = matrix_distances[list(range(0,matrix_distances.shape[0])), matches_12_top2[:, 0]] / matrix_distances[list(range(0,matrix_distances.shape[0])), matches_12_top2[:, 1]] < threshold\n",
    "\n",
    "    # Retrieve top 2 nearest neighbors 1->2.\n",
    "    matches_21_top2 = np.argsort(-matrix_similarity.T, axis = 1)[:, 0:2]\n",
    "    matches_21 = matches_21_top2[:, 0] # Save first NN and match similarity.\n",
    "    \n",
    "    matrix_distances_T = np.sqrt(2 - 2 * matrix_similarity.T)\n",
    "    \n",
    "    # Compute Lowe's ratio.\n",
    "    mask2_good_matches = matrix_distances_T[list(range(0,matrix_distances_T.shape[0])), matches_21_top2[:, 0]] / matrix_distances_T[list(range(0,matrix_distances_T.shape[0])), matches_21_top2[:, 1]] < threshold\n",
    "        \n",
    "    final_mask_good_matches = mask1_good_matches & mask2_good_matches[matches_12]\n",
    "    \n",
    "    # Mutual NN + symmetric ratio test.\n",
    "    ids1 = np.arange(0, matrix_similarity.shape[0])\n",
    "    \n",
    "    mask_mutual_matches = (ids1 == matches_21[matches_12]) & final_mask_good_matches\n",
    "    \n",
    "    if np.any(mask_mutual_matches):\n",
    "        mutual_matches = matches[mask_mutual_matches, :]\n",
    "        \n",
    "        if mutual_matches.shape[0] > MIN_MATCH_COUNT:\n",
    "            final_matches = mutual_matches\n",
    "        \n",
    "        print(\"mutual and good matches/matches - %d/%d\" % (mutual_matches.shape[0],matches.shape[0]))\n",
    "\n",
    "    return final_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uE1dElqtSHkM"
   },
   "outputs": [],
   "source": [
    "def siftMatch(img1, sift_path_ref, sift_path_image, threshold = 0.75, N = 1):\n",
    "    \n",
    "    global NUM_MATCH, subsampling\n",
    "\n",
    "    data_ref = scipy.io.loadmat(sift_path_ref)\n",
    "    dst = data_ref['p'] # (2,N) numpy array, where N is the total number of keypoints\n",
    "    des_dest = data_ref['d'] # (128,N) numpy array, where N is the total number of keypoints\n",
    "        \n",
    "    data_image = scipy.io.loadmat(sift_path_image)\n",
    "    src = data_image['p'] # (2,N) numpy array, where N is the total number of keypoints\n",
    "    des_src = data_image['d'] # (128,N) numpy array, where N is the total number of keypoints\n",
    "        \n",
    "    if subsampling:\n",
    "        h, w, _ = img1.shape\n",
    "            \n",
    "        h_subsampling = math.floor(h/4) \n",
    "            \n",
    "        w_subsampling = math.floor(w * h/(NUM_MATCH*h_subsampling)) \n",
    "            \n",
    "        regions_h = range(0, h+1, h_subsampling)\n",
    "        regions_w = range(0, w+1, w_subsampling)\n",
    "            \n",
    "        des_src_subsampling = np.array([], dtype=np.int64).reshape(des_src.shape[0],0)\n",
    "        src_subsampling = np.array([], dtype=np.int64).reshape(src.shape[0],0)\n",
    "            \n",
    "        id_descriptor = np.arange(des_src.shape[1])\n",
    "            \n",
    "        for i in range(len(regions_h)-1):\n",
    "            h_region_min = regions_h[i]\n",
    "            h_region_max = regions_h[i+1]-1\n",
    "            \n",
    "            for j in range(len(regions_w)-1):\n",
    "                w_region_min = regions_w[j]\n",
    "                w_region_max = regions_w[j+1]-1\n",
    "                    \n",
    "                ind_keypoints_region = (src[0,:] > w_region_min) & (src[0,:] < w_region_max) & (src[1,:] > h_region_min) & (src[1,:] < h_region_max)\n",
    "                    \n",
    "                if np.any(ind_keypoints_region):\n",
    "                    if len(ind_keypoints_region[ind_keypoints_region == True]) < N:\n",
    "                        num_sampling = len(ind_keypoints_region[ind_keypoints_region == True])\n",
    "                            \n",
    "                    else:\n",
    "                        num_sampling = N \n",
    "                        \n",
    "                    ind_d_des = random.sample(list(id_descriptor[ind_keypoints_region]), num_sampling)\n",
    "                        \n",
    "                    des_src_subsampling = np.concatenate((des_src_subsampling, des_src[:, ind_d_des]), axis = 1)\n",
    "                    src_subsampling = np.concatenate((src_subsampling, src[:, ind_d_des]), axis = 1)\n",
    "            \n",
    "        des_src = des_src_subsampling\n",
    "        src = src_subsampling\n",
    "            \n",
    "    m =match_features(des_src,des_dest, threshold)\n",
    "        \n",
    "    matches_coords = np.concatenate((src[:, m[:,0]], dst[:, m[:, 1]]))\n",
    "        \n",
    "    src_pts = matches_coords[0:2, :].T\n",
    "    dst_pts = matches_coords[2:4, :].T\n",
    "            \n",
    "    return src_pts, dst_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SqLigJ92IisO"
   },
   "outputs": [],
   "source": [
    "def FitHomography(selected_matches, N = 4):\n",
    "    \"\"\" Compute the fitted homography matrix by using N match pairs\n",
    "  \n",
    "   [u]     [X]\n",
    "   [v] = H [Y], \n",
    "   [1]     [1]\n",
    "   being H a 3x3 matrix \n",
    "  \n",
    "   This can be arranged in a system Ax = 0, where x is a column vector with \n",
    "   the parameters of the homography, and A is given by:\n",
    "   A = [X Y 1 0 0 0 -u.X -u.Y -u]\n",
    "       [0 0 0 X Y 1 -v.X -v.Y -v]\n",
    "\n",
    "   For N matches, the above matrix is vertically stacked, with 2 rows per match \n",
    "  \"\"\"\n",
    "    \n",
    "    X = selected_matches[:,0]\n",
    "    Y = selected_matches[:,1]\n",
    "    u = selected_matches[:,2]\n",
    "    v = selected_matches[:,3]\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        row_1 = np.array([X[i], Y[i], 1, 0, 0, 0, -X[i]*u[i], -Y[i]*u[i], -u[i]])\n",
    "        row_2 = np.array([0, 0, 0, X[i], Y[i], 1, -X[i]*v[i], -Y[i]*v[i], -v[i]])\n",
    "        \n",
    "        A.append(row_1)\n",
    "        A.append(row_2)\n",
    "        \n",
    "    A = np.array(A)\n",
    "    \n",
    "    # V = eigvec(A.T @ A), being V.T obtained through Singular Value Decomposition (SVD)\n",
    "    _, _, vT = np.linalg.svd(A)\n",
    "\n",
    "  # vT is a 9×9 matrix\n",
    "  # the solution x is the eigenvector corresponding to the smallest eigenvalue, \n",
    "  # that is, the eigenvector corresponding to the minimum singular value, \n",
    "  # leading to a row vector of 9 columns. Thus, to obtain the calibrated \n",
    "  # homography H, the final solution is to reshape the obtained vector into a \n",
    "  # 3x3 matrix \n",
    "    H = np.reshape(vT[-1,:], (3,3))\n",
    "    \n",
    "    # normalized homography, dividing by the element at (3,3)\n",
    "    H = H/H[2,2]\n",
    "    \n",
    "    return H "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TGCDEun9IjWz"
   },
   "outputs": [],
   "source": [
    "def get_errors(all_matches, H):\n",
    "    \"\"\"Compute error or distance between original points and transformed by H. \n",
    "   Return an array of errors for all points\"\"\"\n",
    "    \n",
    "    num_matches = len(all_matches)\n",
    "    \n",
    "    X = all_matches[:,0].reshape(-1, 1)\n",
    "    Y = all_matches[:,1].reshape(-1, 1)\n",
    "    u = all_matches[:,2].reshape(-1, 1)\n",
    "    v = all_matches[:,3].reshape(-1, 1)\n",
    "    \n",
    "    # all matching points in source image\n",
    "    all_p1 = np.concatenate((X, Y, np.ones((len(all_matches),1))), axis = 1)\n",
    "    \n",
    "    # all matching points in template image\n",
    "    all_p2 = np.concatenate((u, v), axis = 1)\n",
    "    \n",
    "    # Transform every point in p1 to estimate p2\n",
    "    estimate_p2homogeneous = H @ all_p1.T\n",
    "    \n",
    "    estimate_p2euclidean = (estimate_p2homogeneous/(estimate_p2homogeneous[-1]))[0:2]\n",
    "    \n",
    "    # Compute error of each matching pair\n",
    "    errors = np.linalg.norm(all_p2 - estimate_p2euclidean.T, axis = 1) \n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "T2oXuUgLIp52"
   },
   "outputs": [],
   "source": [
    "def GetHomographyRANSAC(match_coords):\n",
    "    \n",
    "    \"\"\"Function that computes linear (2D) Homography Calibration, implementing RANSAC\n",
    "  for eliminating outliers and align correspondent matches. The main output concerns \n",
    "  a single transformation H that gets the most inliers in the course of all the \n",
    "  iterations. \n",
    "  \n",
    "    Args:\n",
    "        match_coords(numpy.ndarray): In dims (#matched pixels, 4).\n",
    "\n",
    "    Returns:\n",
    "        H(numpy.ndarray): Homography matrix, dims (3, 3).\n",
    "    \"\"\"\n",
    "    \n",
    "    global MAX_ITER, threshold_error\n",
    "    \n",
    "    N = 4 # four matches to initialize the homography in each iteration\n",
    "    \n",
    "    max_inliers = 0 \n",
    "    \n",
    "    # RANSAC procedure\n",
    "    for itr in range(MAX_ITER): \n",
    "        # Randomly select 4 matched pairs\n",
    "        idx_rand_inliers = random.sample(range(match_coords.shape[0]), N)\n",
    "        \n",
    "        selected_matches = match_coords[idx_rand_inliers, :]\n",
    "        \n",
    "        # compute the homography H by DLT from the N = 4 matched pairs \n",
    "        H = FitHomography(selected_matches)\n",
    "        \n",
    "        # Find inliners \n",
    "        errors = get_errors(match_coords, H)\n",
    "        \n",
    "        idx_inliers = np.where(errors < threshold_error)[0]\n",
    "        \n",
    "        num_inliers = len(idx_inliers) \n",
    "        \n",
    "        # Analise current solution, and if it contains the maximum number of inliers\n",
    "        # amongst all homographies until now fitted, save the current inliers for \n",
    "        # further refinement of the homography in the last step \n",
    "        \n",
    "        if num_inliers > max_inliers:\n",
    "            max_inliers = num_inliers\n",
    "            best_inliers = match_coords[idx_inliers]\n",
    "    \n",
    "    # compute the homography H by DLT from best_inliers  \n",
    "    H = FitHomography(best_inliers, max_inliers)\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Xlq83FXHpThV"
   },
   "outputs": [],
   "source": [
    "def compute_H_wrt_reference(H_all, ref_image):\n",
    "    \"\"\"\n",
    "  Function that computes new homographies H_map that map every other image *directly* to\n",
    "  the reference image by composing H matrices in H_all. \n",
    "  The homography in H_map that is associated with the reference image\n",
    "  should be the identity matrix, created using eye(3). The homographies in\n",
    "  H_map for the other images (both before and after the reference image)\n",
    "  are computed by using already defined matrices in H_map and H_all. \n",
    "\n",
    "  Args: \n",
    "      H_all(cell array) \n",
    "\n",
    "      ref_image(int): index of the reference image (the first image has index 1)\n",
    "\n",
    "\n",
    "  Returns:\n",
    "      H_map(cell array): 3x3 homographies matrices that map each image into the reference image's\n",
    "  coordinate system.\n",
    "\n",
    "  \"\"\"\n",
    "    num_imgs = len(H_all)+1\n",
    "    \n",
    "    H_map = {}\n",
    "    \n",
    "    key = \"H{}{}\".format(ref_image-1, ref_image-1) \n",
    "    H_map[key] = np.eye(3)\n",
    "    \n",
    "    for i in range(0, ref_image-1): \n",
    "        key = \"H{}{}\".format(i, ref_image-1)  \n",
    "        H_aux = np.eye(3)\n",
    "        \n",
    "        j = i\n",
    "        \n",
    "        while j < ref_image - 1:\n",
    "            key_t = \"H{}{}\".format(j, j+1)\n",
    "            H_aux = H_all[key_t] @ H_aux\n",
    "            j += 1 \n",
    "        \n",
    "        H_map[key] = H_aux\n",
    "    \n",
    "    for i in range(ref_image, num_imgs):\n",
    "        key = \"H{}{}\".format(i, ref_image-1)  # H10\n",
    "        H_aux = np.eye(3)\n",
    "        \n",
    "        j = i -1 \n",
    "        \n",
    "        while j>= ref_image-1:\n",
    "            key_t = \"H{}{}\".format(j, j+1)\n",
    "            H_inv = np.linalg.inv(H_all[key_t])\n",
    "            H_aux = H_inv/H_inv[2,2] @ H_aux\n",
    "            j -= 1\n",
    "        \n",
    "        H_map[key] = H_aux\n",
    "    \n",
    "    return H_map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Homography(H):\n",
    "    \"\"\"\n",
    "  Check if homography is reasonable, according to certain criteria:\n",
    "  - If the determinant of the homography det(H) is very close to 0, H is \n",
    "   close to singular;\n",
    "  \n",
    "  - If condition number of H (ratio of the first-to-last singular value) is\n",
    "    infinite, the matrix H is singular, and if it is too large, H is \n",
    "    ill-conditioned. In non-mathematical terms, an ill-conditioned problem \n",
    "    is one where, for a small change in the inputs, there is a large \n",
    "    change in the output, that is, H is very sensitive to changes or errors \n",
    "    in the input. This means that the correct solution/answer to the \n",
    "    equation becomes hard to find;\n",
    "        \n",
    "  - If det(H) >>, the invert matrix would have a determinant too close \n",
    "    to 0, that is, H^-1 would be close to singular;\n",
    "        \n",
    "  - If det(H) < 0, the homography is not conserving the orientation, \n",
    "    being orientation-reversing. This is not suitable, except if we are \n",
    "    watching the object in a mirror. Nevertheless, sift/surf descriptors \n",
    "    are not done to be mirror invariant, so if it was the case we would \n",
    "    probably not have good maches. \n",
    "        \n",
    "  An exactly singular matrix means that it is not invertible. If the above \n",
    "  criteria is verified, more pratically the matrix H or H^-1 is non-invertible. \n",
    "  In the context of homographies, it means that points in one 2D image are mapped\n",
    "  to a less-than-2D subspace in the other image (a line, a point), i.e. \n",
    "  the estimated homography would be warping the image into nothing. A \n",
    "  nearly singular matrix is indicative of a rather extreme warp.  \n",
    "  \"\"\"\n",
    "    \n",
    "    #Conditions to accertain that the resultant homography H is free of \n",
    "    #singularities. If one of the condition is satisfied, the Homography H from \n",
    "    #image space to reference image space is not reasonable, according \n",
    "    #to the defined criteria \n",
    "    if  np.linalg.det(H) < 1 and np.linalg.cond(H[0:2, 0:2]) > 2:\n",
    "        \n",
    "        # In the condition number, only the top-left 2x2 matrix is considered, \n",
    "        # thus omitting the z-dependence of the transformation, which should be \n",
    "        # irrelevant because we know that z will always be fixed to 1 on the input\n",
    "        \n",
    "        H = np.zeros((3,3))\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7Yp71lRiKgAu"
   },
   "outputs": [],
   "source": [
    "def pivproject2022_task2(ref_image, path_to_input_folder, path_to_output_folder):\n",
    "    \n",
    "    \"\"\"\n",
    "  Compute the homographies between images in a directory and a reference image\n",
    "\n",
    "    ref_image: integer with index number of the frame that will be the reference \n",
    "    image. First image is index=1. Ideally, the one in the middle of the sequence \n",
    "    of input images so that there is less distortion resulting mosaic.\n",
    "    \n",
    "    path_to_input_folder: string with the path to the input folder, where input images \n",
    "                           and keypoints are stored. Images are named rgb_number.jpg \n",
    "                           (or rgb_number.png) and corresponding keypoints are named \n",
    "                           rgbsift_number.mat\n",
    "\n",
    "    \n",
    "    path_to_output_folder: string with the path where homographies with respect to the reference\n",
    "    image are stored\n",
    "\n",
    "  \"\"\"\n",
    "    \n",
    "    # Check if path_to_input_folder was passed. If not, \"No_path\" is assigned\n",
    "    if not('path_to_input_folder' in locals()):\n",
    "        path_to_input_folder = \"No_path\";\n",
    "    \n",
    "    # Check if output directory exists. If not, output directory is created \n",
    "    if not(os.path.isdir(path_to_output_folder)):\n",
    "        os.mkdir(path_to_output_folder)\n",
    "    \n",
    "    # Get input rgb images\n",
    "    rgb_paths = []\n",
    "    sift_paths = []\n",
    "    \n",
    "    for im_path in glob.glob(path_to_input_folder+'/*.jpg'):\n",
    "        rgb_paths.append(im_path)\n",
    "    \n",
    "    if len(rgb_paths) == 0:\n",
    "        print('ERROR: In the specified path there aren\\'t image input files')\n",
    "        return \n",
    "    \n",
    "    else: \n",
    "        #Ordering the rgb_paths array, in such a way that consecutive frames follow \n",
    "        #each other  \n",
    "        image_paths = sorted(rgb_paths)  \n",
    "    \n",
    "    print('Searching for sift .mat files')\n",
    "        \n",
    "    for im_path in glob.glob(path_to_input_folder+'/*.mat'):\n",
    "        sift_paths.append(im_path)\n",
    "    \n",
    "    if len(sift_paths) != 0:\n",
    "        sift_paths_ordered = sorted(sift_paths)\n",
    "    \n",
    "    else:\n",
    "        print('ERROR: In the specified path there aren\\'t sift input files.')\n",
    "        return \n",
    "    \n",
    "    # Get Reference image\n",
    "    try: \n",
    "        reference_image = img.imread(image_paths[ref_image - 1])\n",
    "        \n",
    "    except:\n",
    "        print('ERROR: The index for the reference image is out of bounds. Please select an index between 1 and %d' % (len(rgb_paths)))\n",
    "        return\n",
    "    \n",
    "    H_all = {}\n",
    "    # compute homography matrices between adjacent input images. Homography matrices \n",
    "    # between adjacent input images are then stored in a cell array H_all.\n",
    "    \n",
    "    for i in range(len(image_paths)-1):\n",
    "        image_1_path = image_paths[i]\n",
    "        image_2_path = image_paths[i+1]\n",
    "        \n",
    "        print(\"Processing {} & {}\".format(image_1_path, image_2_path))\n",
    "        \n",
    "        image_1 = img.imread(image_1_path)\n",
    "        image_2 = img.imread(image_2_path)\n",
    "        \n",
    "        sift_path1 = sift_paths_ordered[i]\n",
    "        sift_path2 = sift_paths_ordered[i+1]\n",
    "        \n",
    "        key = 'H{}{}'.format(i, i+1)\n",
    "        \n",
    "        try:\n",
    "            # coordinates of the matches between image and template \n",
    "            m_coords_img, m_coords_temp = siftMatch(image_1, sift_path2, sift_path1, N = 4)\n",
    "            match_coords = np.append(m_coords_img, m_coords_temp, axis = 1)\n",
    "        \n",
    "        except:\n",
    "            print('ERROR: check format of directory, as img.imread only accepts ASCII characters for image paths')\n",
    "            return \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            H_all[key] = GetHomographyRANSAC(match_coords)\n",
    "            \n",
    "        except: \n",
    "            print('ERROR: RANSAC failed to compute homography. Check if there are enough matching keypoints.')\n",
    "        \n",
    "    # Compute new homographies H_map that map every other image *directly* to\n",
    "    # the reference image \n",
    "    H_map = compute_H_wrt_reference(H_all, ref_image)\n",
    "    \n",
    "    for i in range(len(H_map)):\n",
    "        key = \"H{}{}\".format(i, ref_image-1)\n",
    "        H = H_map[key]\n",
    "        \n",
    "        print(\"image \"+str(i))\n",
    "        print(\"np.linalg.det(H):\", np.linalg.det(H)) \n",
    "        print(\"np.linalg.cond(H[0:2, 0:2]):\", np.linalg.cond(H[0:2, 0:2]))\n",
    "            \n",
    "        H = Check_Homography(H)\n",
    "\n",
    "        if np.array_equal(H, np.zeros((3,3))):\n",
    "            print(\"H{}{} is not reasonable\".format(i, ref_image-1))\n",
    "        else:\n",
    "            print(\"H{}{} is reasonable\".format(i, ref_image-1))\n",
    "\n",
    "        # saving homographies with respect to the reference image \n",
    "        file_name = os.path.split(image_paths[i])[1]\n",
    "        H_output_path = path_to_output_folder + '/' + 'H_' + file_name[4:8] + '.mat'\n",
    "        scipy.io.savemat(H_output_path, {'H':H})\n",
    "    \n",
    "    print('All projections calculated.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "xmx6qS2Y3PHG",
    "outputId": "6b8b2454-2a09-4b68-f5ee-aff996e1c762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for jpg images\n",
      "Searching for sift .mat files\n",
      "Processing DATASETS/quarto/rgb_0001.jpg & DATASETS/quarto/rgb_0002.jpg\n",
      "good matches/matches - 63/431\n",
      "mutual and good matches/matches - 32/431\n",
      "Processing DATASETS/quarto/rgb_0002.jpg & DATASETS/quarto/rgb_0003.jpg\n",
      "good matches/matches - 35/573\n",
      "mutual and good matches/matches - 20/573\n",
      "image 0\n",
      "np.linalg.det(H): 1.0\n",
      "np.linalg.cond(H[0:2, 0:2]): 1.0\n",
      "H00 is reasonable\n",
      "image 1\n",
      "np.linalg.det(H): 3.5710435736999515\n",
      "np.linalg.cond(H[0:2, 0:2]): 1.6715923227010254\n",
      "H10 is reasonable\n",
      "image 2\n",
      "np.linalg.det(H): 3.214570741778466\n",
      "np.linalg.cond(H[0:2, 0:2]): 2.061826286240154\n",
      "H20 is reasonable\n",
      "All projections calculated.\n"
     ]
    }
   ],
   "source": [
    "pivproject2022_task2(1, 'DATASETS/quarto', 'Output_folder_quarto')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
